{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import config\n",
    "import utils\n",
    "import main_multi as mt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41734/41734 [00:01<00:00, 26248.06it/s]\n"
     ]
    }
   ],
   "source": [
    "SOURCE_DATASET = 'BeijingPM'\n",
    "\n",
    "data_root_dir = f'./data/{SOURCE_DATASET}/'\n",
    "file = [file for file in os.listdir(data_root_dir) if file.endswith('.csv')]\n",
    "data = pd.read_csv(os.path.join(data_root_dir, file[0]))\n",
    "data.dropna(inplace=True)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data = data[[ 'DEWP', 'TEMP', 'PRES', 'Iws', 'pm2.5', 'cbwd']] # Multi-task learning\n",
    "\n",
    "def sequence_preprocessing(data_x, data_y_1, data_y_2, timestep, shift_size):\n",
    "    X = []\n",
    "    targets_1 = []\n",
    "    targets_2 = []\n",
    "\n",
    "    # Slicing\n",
    "    for start_idx in  tqdm(range(0, data_x.shape[0] - timestep + 1, shift_size)):\n",
    "        X.append(data_x[start_idx:start_idx + timestep])\n",
    "\n",
    "        ### Method1. Last (Window의 마지막 값을 Label로 활용)\n",
    "\n",
    "        targets_1.append(data_y_1.values[start_idx + timestep - 1])\n",
    "        targets_2.append(data_y_2.values[start_idx + timestep - 1])\n",
    "\n",
    "    # Make to array \n",
    "    X = np.array(X)\n",
    "    targets_1 = np.array(targets_1)\n",
    "    targets_2 = np.array(targets_2)\n",
    "    \n",
    "\n",
    "    # (Instace, Features, Timestep)\n",
    "    X = X.transpose(0, 2, 1)\n",
    "\n",
    "    return X, targets_1, targets_2\n",
    "\n",
    "data_target = data.copy()\n",
    "\n",
    "data_x = data_target[['DEWP', 'TEMP', 'PRES', 'Iws']]\n",
    "data_y_1 = data_target[['cbwd']]\n",
    "data_y_2 = data_target[['pm2.5']]\n",
    "\n",
    "seq_len = 24\n",
    "x, y_1, y_2 = sequence_preprocessing(data_x, data_y_1, data_y_2, timestep=seq_len, shift_size=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_1 = label_encoder.fit_transform(y_1)\n",
    "\n",
    "data_type = 'data_multi'\n",
    "\n",
    "if data_type == 'data_single_1':\n",
    "    x = x.copy()\n",
    "    y = y_1.copy()\n",
    "    \n",
    "elif data_type == 'data_single_2':\n",
    "    x = x.copy()\n",
    "    y = y_2.copy()\n",
    "\n",
    "elif data_type == 'data_multi':\n",
    "    x = x.copy()\n",
    "    y = np.concatenate([y_1.reshape(-1,1), y_2], axis=1)\n",
    "    \n",
    "\n",
    "split_ratio = 0.2\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=split_ratio, shuffle=False, random_state=502)\n",
    "# TODO: Add scaler\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=split_ratio, shuffle=True, random_state=502)\n",
    "\n",
    "input_size = train_x.shape[1]\n",
    "\n",
    "if data_type == 'data_single_1':\n",
    "    num_classes = 1\n",
    "\n",
    "elif data_type == 'data_single_2':\n",
    "    num_classes = 4\n",
    "\n",
    "    \n",
    "else:\n",
    "    num_classes_1 = 4\n",
    "    num_classes_2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6258536000958428\n",
      "8888.908669055698\n",
      "2.3142763978638214\n",
      "69.81605159146666\n",
      "0.00046365049896623933\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM_FCNs_multi'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "model_params['parameter']['input_size'] = input_size\n",
    "model_params['best_model_path'] = f'./ckpt/{SOURCE_DATASET}/lstm_fcn_pre_cls_fine.pt'\n",
    "\n",
    "data_target = mt.Multilearning(model_params,'self') \n",
    "\n",
    "pred, acc, mse, MAPE, MAE, R2 = data_target.pred_data(test_x, test_y, best_model_path = model_params['best_model_path'])\n",
    "\n",
    "pred.to_csv(f'./save/lstm_fcn_pre_cls_fine.csv', index=False)\n",
    "print(acc)\n",
    "print(mse)\n",
    "print(MAPE)\n",
    "print(MAE)\n",
    "print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6572421229184138\n",
      "8959.45117766987\n",
      "2.21100940084827\n",
      "68.78223809479553\n",
      "-0.007468684523252556\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM_FCNs_multi'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "model_params['parameter']['input_size'] = input_size\n",
    "model_params['best_model_path'] = f'./ckpt/{SOURCE_DATASET}/lstm_fcn_pre_reg_fine.pt'\n",
    "\n",
    "data_target = mt.Multilearning(model_params,'self') \n",
    "\n",
    "pred, acc, mse, MAPE, MAE, R2 = data_target.pred_data(test_x, test_y, best_model_path = model_params['best_model_path'])\n",
    "\n",
    "pred.to_csv(f'./save/lstm_fcn_pre_reg_fine.csv', index=False)\n",
    "print(acc)\n",
    "print(mse)\n",
    "print(MAPE)\n",
    "print(MAE)\n",
    "print(R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
