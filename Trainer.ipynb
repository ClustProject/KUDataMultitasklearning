{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import config\n",
    "import utils\n",
    "import main_multi as mt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41734/41734 [00:01<00:00, 25745.82it/s]\n"
     ]
    }
   ],
   "source": [
    "SOURCE_DATASET = 'BeijingPM'\n",
    "\n",
    "data_root_dir = f'./data/{SOURCE_DATASET}/'\n",
    "file = [file for file in os.listdir(data_root_dir) if file.endswith('.csv')]\n",
    "data = pd.read_csv(os.path.join(data_root_dir, file[0]))\n",
    "data.dropna(inplace=True)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data = data[[ 'DEWP', 'TEMP', 'PRES', 'Iws', 'pm2.5', 'cbwd']] # Multi-task learning\n",
    "\n",
    "data[['cbwd']].value_counts() # 4 class classification\n",
    "\n",
    "def sequence_preprocessing(data_x, data_y_1, data_y_2, timestep, shift_size):\n",
    "    X = []\n",
    "    targets_1 = []\n",
    "    targets_2 = []\n",
    "\n",
    "    # Slicing\n",
    "    for start_idx in  tqdm(range(0, data_x.shape[0] - timestep + 1, shift_size)):\n",
    "        X.append(data_x[start_idx:start_idx + timestep])\n",
    "\n",
    "        ### Method1. Last (Window의 마지막 값을 Label로 활용)\n",
    "\n",
    "        targets_1.append(data_y_1.values[start_idx + timestep - 1])\n",
    "        targets_2.append(data_y_2.values[start_idx + timestep - 1])\n",
    "\n",
    "    # Make to array \n",
    "    X = np.array(X)\n",
    "    targets_1 = np.array(targets_1)\n",
    "    targets_2 = np.array(targets_2)\n",
    "    \n",
    "\n",
    "    # (Instace, Features, Timestep)\n",
    "    X = X.transpose(0, 2, 1)\n",
    "\n",
    "    return X, targets_1, targets_2\n",
    "\n",
    "data_target = data.copy()\n",
    "\n",
    "data_x = data_target[['DEWP', 'TEMP', 'PRES', 'Iws']]\n",
    "data_y_1 = data_target[['cbwd']]\n",
    "data_y_2 = data_target[['pm2.5']]\n",
    "\n",
    "seq_len = 24\n",
    "x, y_1, y_2 = sequence_preprocessing(data_x, data_y_1, data_y_2, timestep=seq_len, shift_size=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_1 = label_encoder.fit_transform(y_1)\n",
    "\n",
    "data_type = 'data_multi'\n",
    "\n",
    "if data_type == 'data_single_1':\n",
    "    x = x.copy()\n",
    "    y = y_1.copy()\n",
    "    \n",
    "elif data_type == 'data_single_2':\n",
    "    x = x.copy()\n",
    "    y = y_2.copy()\n",
    "\n",
    "elif data_type == 'data_multi':\n",
    "    x = x.copy()\n",
    "    y = np.concatenate([y_1.reshape(-1,1), y_2], axis=1)\n",
    "    \n",
    "split_ratio = 0.2\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=split_ratio, shuffle=False, random_state=502)\n",
    "# TODO: Add scaler\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=split_ratio, shuffle=True, random_state=502)\n",
    "\n",
    "input_size = train_x.shape[1]\n",
    "\n",
    "if data_type == 'data_single_1':\n",
    "    num_classes = 1\n",
    "\n",
    "elif data_type == 'data_single_2':\n",
    "    num_classes = 4\n",
    "\n",
    "    \n",
    "else:\n",
    "    num_classes_1 = 4\n",
    "    num_classes_2 = 1\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/500\n",
      "train Loss: 1.1988 Acc: 0.4785\n",
      "val Loss: 1.1644 Acc: 0.4747\n",
      "\n",
      "Epoch 10/500\n",
      "train Loss: 0.8656 Acc: 0.6501\n",
      "val Loss: 1.0207 Acc: 0.5494\n",
      "\n",
      "Epoch 20/500\n",
      "train Loss: 0.7954 Acc: 0.6735\n",
      "val Loss: 1.0128 Acc: 0.6047\n",
      "\n",
      "Epoch 30/500\n",
      "train Loss: 0.7630 Acc: 0.6853\n",
      "val Loss: 0.8073 Acc: 0.6689\n",
      "\n",
      "Epoch 40/500\n",
      "train Loss: 0.7384 Acc: 0.6936\n",
      "val Loss: 0.9204 Acc: 0.6108\n",
      "\n",
      "Epoch 50/500\n",
      "train Loss: 0.7168 Acc: 0.7038\n",
      "val Loss: 0.7774 Acc: 0.6849\n",
      "\n",
      "Epoch 60/500\n",
      "train Loss: 0.7003 Acc: 0.7091\n",
      "val Loss: 1.0650 Acc: 0.6030\n",
      "\n",
      "Epoch 70/500\n",
      "train Loss: 0.6853 Acc: 0.7153\n",
      "val Loss: 0.7611 Acc: 0.6821\n",
      "\n",
      "Epoch 80/500\n",
      "train Loss: 0.6700 Acc: 0.7213\n",
      "val Loss: 0.7987 Acc: 0.6724\n",
      "\n",
      "Epoch 90/500\n",
      "train Loss: 0.6545 Acc: 0.7289\n",
      "val Loss: 0.8290 Acc: 0.6721\n",
      "\n",
      "Epoch 100/500\n",
      "train Loss: 0.6431 Acc: 0.7320\n",
      "val Loss: 0.8548 Acc: 0.6577\n",
      "\n",
      "Epoch 110/500\n",
      "train Loss: 0.6283 Acc: 0.7389\n",
      "val Loss: 0.7877 Acc: 0.6783\n",
      "\n",
      "Epoch 120/500\n",
      "train Loss: 0.6187 Acc: 0.7421\n",
      "val Loss: 0.9982 Acc: 0.6213\n",
      "\n",
      "Epoch 130/500\n",
      "train Loss: 0.6060 Acc: 0.7491\n",
      "val Loss: 0.8824 Acc: 0.6520\n",
      "\n",
      "Epoch 140/500\n",
      "train Loss: 0.5966 Acc: 0.7544\n",
      "val Loss: 1.6025 Acc: 0.5019\n",
      "\n",
      "Epoch 150/500\n",
      "train Loss: 0.5846 Acc: 0.7604\n",
      "val Loss: 0.8553 Acc: 0.6697\n",
      "\n",
      "Epoch 160/500\n",
      "train Loss: 0.5780 Acc: 0.7638\n",
      "val Loss: 1.0173 Acc: 0.6225\n",
      "\n",
      "Epoch 170/500\n",
      "train Loss: 0.5715 Acc: 0.7651\n",
      "val Loss: 0.8142 Acc: 0.6664\n",
      "\n",
      "Epoch 180/500\n",
      "train Loss: 0.5658 Acc: 0.7678\n",
      "val Loss: 1.0154 Acc: 0.6219\n",
      "\n",
      "Epoch 190/500\n",
      "train Loss: 0.5553 Acc: 0.7721\n",
      "val Loss: 0.7945 Acc: 0.6849\n",
      "\n",
      "Epoch 200/500\n",
      "train Loss: 0.5445 Acc: 0.7755\n",
      "val Loss: 0.7827 Acc: 0.6789\n",
      "\n",
      "Epoch 210/500\n",
      "train Loss: 0.5388 Acc: 0.7797\n",
      "val Loss: 0.9012 Acc: 0.6456\n",
      "\n",
      "Epoch 220/500\n",
      "train Loss: 0.5381 Acc: 0.7800\n",
      "val Loss: 0.7289 Acc: 0.7037\n",
      "\n",
      "Epoch 230/500\n",
      "train Loss: 0.5237 Acc: 0.7875\n",
      "val Loss: 0.8441 Acc: 0.6776\n",
      "\n",
      "Epoch 240/500\n",
      "train Loss: 0.5147 Acc: 0.7917\n",
      "val Loss: 0.9028 Acc: 0.6848\n",
      "\n",
      "Epoch 250/500\n",
      "train Loss: 0.5140 Acc: 0.7898\n",
      "val Loss: 0.8552 Acc: 0.6680\n",
      "\n",
      "Epoch 260/500\n",
      "train Loss: 0.5003 Acc: 0.7945\n",
      "val Loss: 1.5594 Acc: 0.5494\n",
      "\n",
      "Epoch 270/500\n",
      "train Loss: 0.5017 Acc: 0.7950\n",
      "val Loss: 1.2828 Acc: 0.5976\n",
      "\n",
      "Epoch 280/500\n",
      "train Loss: 0.4877 Acc: 0.8019\n",
      "val Loss: 0.9907 Acc: 0.6252\n",
      "\n",
      "Epoch 290/500\n",
      "train Loss: 0.4947 Acc: 0.7985\n",
      "val Loss: 0.7819 Acc: 0.7023\n",
      "\n",
      "Epoch 300/500\n",
      "train Loss: 0.4836 Acc: 0.8022\n",
      "val Loss: 0.7461 Acc: 0.6974\n",
      "\n",
      "Epoch 310/500\n",
      "train Loss: 0.4776 Acc: 0.8047\n",
      "val Loss: 0.9301 Acc: 0.6316\n",
      "\n",
      "Epoch 320/500\n",
      "train Loss: 0.4737 Acc: 0.8064\n",
      "val Loss: 0.7882 Acc: 0.7008\n",
      "\n",
      "Epoch 330/500\n",
      "train Loss: 0.4638 Acc: 0.8099\n",
      "val Loss: 0.9479 Acc: 0.6512\n",
      "\n",
      "Epoch 340/500\n",
      "train Loss: 0.4601 Acc: 0.8116\n",
      "val Loss: 0.9840 Acc: 0.6668\n",
      "\n",
      "Epoch 350/500\n",
      "train Loss: 0.4565 Acc: 0.8150\n",
      "val Loss: 1.1182 Acc: 0.6375\n",
      "\n",
      "Epoch 360/500\n",
      "train Loss: 0.4534 Acc: 0.8148\n",
      "val Loss: 0.8539 Acc: 0.6658\n",
      "\n",
      "Epoch 370/500\n",
      "train Loss: 0.4462 Acc: 0.8191\n",
      "val Loss: 0.8163 Acc: 0.6861\n",
      "\n",
      "Epoch 380/500\n",
      "train Loss: 0.4451 Acc: 0.8163\n",
      "val Loss: 0.8997 Acc: 0.6855\n",
      "\n",
      "Epoch 390/500\n",
      "train Loss: 0.4395 Acc: 0.8217\n",
      "val Loss: 0.8022 Acc: 0.6945\n",
      "\n",
      "Epoch 400/500\n",
      "train Loss: 0.4340 Acc: 0.8235\n",
      "val Loss: 0.9555 Acc: 0.6742\n",
      "\n",
      "Epoch 410/500\n",
      "train Loss: 0.4327 Acc: 0.8232\n",
      "val Loss: 0.9057 Acc: 0.6915\n",
      "\n",
      "Epoch 420/500\n",
      "train Loss: 0.4266 Acc: 0.8262\n",
      "val Loss: 1.0415 Acc: 0.6144\n",
      "\n",
      "Epoch 430/500\n",
      "train Loss: 0.4259 Acc: 0.8266\n",
      "val Loss: 1.0349 Acc: 0.6842\n",
      "\n",
      "Epoch 440/500\n",
      "train Loss: 0.4228 Acc: 0.8296\n",
      "val Loss: 1.0427 Acc: 0.6457\n",
      "\n",
      "Epoch 450/500\n",
      "train Loss: 0.4165 Acc: 0.8313\n",
      "val Loss: 0.8182 Acc: 0.6867\n",
      "\n",
      "Epoch 460/500\n",
      "train Loss: 0.4094 Acc: 0.8339\n",
      "val Loss: 1.2785 Acc: 0.6161\n",
      "\n",
      "Epoch 470/500\n",
      "train Loss: 0.4109 Acc: 0.8341\n",
      "val Loss: 0.8318 Acc: 0.6924\n",
      "\n",
      "Epoch 480/500\n",
      "train Loss: 0.4054 Acc: 0.8346\n",
      "val Loss: 1.0537 Acc: 0.6201\n",
      "\n",
      "Epoch 490/500\n",
      "train Loss: 0.4048 Acc: 0.8367\n",
      "val Loss: 1.4331 Acc: 0.5791\n",
      "\n",
      "Epoch 500/500\n",
      "train Loss: 0.4005 Acc: 0.8390\n",
      "val Loss: 0.8031 Acc: 0.7058\n",
      "\n",
      "Training complete in 20m 13s\n",
      "Best val Acc: 0.725966\n"
     ]
    }
   ],
   "source": [
    "# Classification pre-training\n",
    "\n",
    "model_name = 'LSTM_FCNs_multi'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "model_params['parameter']['input_size'] = input_size\n",
    "model_params['parameter']['alpha'] = 1 # cls = alpha, reg = 1-alpha\n",
    "model_params['best_model_path'] = f'./ckpt/{SOURCE_DATASET}/lstm_fcn_multi_{seq_len}_pre_cls.pt'\n",
    "\n",
    "data_source = mt.Multilearning(model_params,'self')\n",
    "data_source.build_model()\n",
    "\n",
    "best_model = data_source.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "\n",
    "os.makedirs(f'./ckpt/{SOURCE_DATASET}/', exist_ok=True)\n",
    "data_source.save_model(best_model, best_model_path=model_params[\"best_model_path\"])  # 모델 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/500\n",
      "train Loss: 0.8965 Acc: 0.4179\n",
      "val Loss: 0.8960 Acc: 0.4377\n",
      "\n",
      "Epoch 10/500\n",
      "train Loss: 0.7783 Acc: 0.2221\n",
      "val Loss: 0.7751 Acc: 0.2074\n",
      "\n",
      "Epoch 20/500\n",
      "train Loss: 0.6248 Acc: 0.1843\n",
      "val Loss: 0.6252 Acc: 0.1682\n",
      "\n",
      "Epoch 30/500\n",
      "train Loss: 0.4956 Acc: 0.1812\n",
      "val Loss: 0.4962 Acc: 0.1751\n",
      "\n",
      "Epoch 40/500\n",
      "train Loss: 0.4279 Acc: 0.1816\n",
      "val Loss: 0.4335 Acc: 0.1780\n",
      "\n",
      "Epoch 50/500\n",
      "train Loss: 0.4175 Acc: 0.1853\n",
      "val Loss: 0.4249 Acc: 0.1739\n",
      "\n",
      "Epoch 60/500\n",
      "train Loss: 0.4173 Acc: 0.1490\n",
      "val Loss: 0.4249 Acc: 0.1617\n",
      "\n",
      "Epoch 70/500\n",
      "train Loss: 0.4172 Acc: 0.1479\n",
      "val Loss: 0.4249 Acc: 0.1385\n",
      "\n",
      "Epoch 80/500\n",
      "train Loss: 0.4173 Acc: 0.1426\n",
      "val Loss: 0.4249 Acc: 0.1373\n",
      "\n",
      "Epoch 90/500\n",
      "train Loss: 0.4171 Acc: 0.1415\n",
      "val Loss: 0.4249 Acc: 0.1390\n",
      "\n",
      "Epoch 100/500\n",
      "train Loss: 0.4172 Acc: 0.1325\n",
      "val Loss: 0.4249 Acc: 0.1336\n",
      "\n",
      "Epoch 110/500\n",
      "train Loss: 0.4170 Acc: 0.1450\n",
      "val Loss: 0.4249 Acc: 0.1277\n",
      "\n",
      "Epoch 120/500\n",
      "train Loss: 0.4168 Acc: 0.1473\n",
      "val Loss: 0.4249 Acc: 0.1234\n",
      "\n",
      "Epoch 130/500\n",
      "train Loss: 0.4168 Acc: 0.1593\n",
      "val Loss: 0.4253 Acc: 0.1292\n",
      "\n",
      "Epoch 140/500\n",
      "train Loss: 0.4169 Acc: 0.1680\n",
      "val Loss: 0.4250 Acc: 0.1337\n",
      "\n",
      "Epoch 150/500\n",
      "train Loss: 0.4167 Acc: 0.1630\n",
      "val Loss: 0.4249 Acc: 0.1337\n",
      "\n",
      "Epoch 160/500\n",
      "train Loss: 0.4168 Acc: 0.1689\n",
      "val Loss: 0.4249 Acc: 0.1447\n",
      "\n",
      "Epoch 170/500\n",
      "train Loss: 0.4167 Acc: 0.1781\n",
      "val Loss: 0.4249 Acc: 0.1544\n",
      "\n",
      "Epoch 180/500\n",
      "train Loss: 0.4168 Acc: 0.1727\n",
      "val Loss: 0.4250 Acc: 0.1563\n",
      "\n",
      "Epoch 190/500\n",
      "train Loss: 0.4167 Acc: 0.1844\n",
      "val Loss: 0.4249 Acc: 0.1511\n",
      "\n",
      "Epoch 200/500\n",
      "train Loss: 0.4169 Acc: 0.1774\n",
      "val Loss: 0.4251 Acc: 0.1533\n",
      "\n",
      "Epoch 210/500\n",
      "train Loss: 0.4167 Acc: 0.1775\n",
      "val Loss: 0.4249 Acc: 0.1447\n",
      "\n",
      "Epoch 220/500\n",
      "train Loss: 0.4167 Acc: 0.1762\n",
      "val Loss: 0.4250 Acc: 0.1430\n",
      "\n",
      "Epoch 230/500\n",
      "train Loss: 0.4167 Acc: 0.1693\n",
      "val Loss: 0.4250 Acc: 0.1442\n",
      "\n",
      "Epoch 240/500\n",
      "train Loss: 0.4167 Acc: 0.1705\n",
      "val Loss: 0.4250 Acc: 0.1524\n",
      "\n",
      "Epoch 250/500\n",
      "train Loss: 0.4165 Acc: 0.1854\n",
      "val Loss: 0.4250 Acc: 0.1560\n",
      "\n",
      "Epoch 260/500\n",
      "train Loss: 0.4165 Acc: 0.1831\n",
      "val Loss: 0.4251 Acc: 0.1586\n",
      "\n",
      "Epoch 270/500\n",
      "train Loss: 0.4164 Acc: 0.1880\n",
      "val Loss: 0.4252 Acc: 0.1580\n",
      "\n",
      "Epoch 280/500\n",
      "train Loss: 0.4164 Acc: 0.1881\n",
      "val Loss: 0.4249 Acc: 0.1626\n",
      "\n",
      "Epoch 290/500\n",
      "train Loss: 0.4166 Acc: 0.1917\n",
      "val Loss: 0.4249 Acc: 0.1733\n",
      "\n",
      "Epoch 300/500\n",
      "train Loss: 0.4165 Acc: 0.1957\n",
      "val Loss: 0.4249 Acc: 0.1779\n",
      "\n",
      "Epoch 310/500\n",
      "train Loss: 0.4165 Acc: 0.1994\n",
      "val Loss: 0.4249 Acc: 0.1713\n",
      "\n",
      "Epoch 320/500\n",
      "train Loss: 0.4161 Acc: 0.2115\n",
      "val Loss: 0.4250 Acc: 0.1742\n",
      "\n",
      "Epoch 330/500\n",
      "train Loss: 0.4165 Acc: 0.2053\n",
      "val Loss: 0.4249 Acc: 0.1768\n",
      "\n",
      "Epoch 340/500\n",
      "train Loss: 0.4164 Acc: 0.2035\n",
      "val Loss: 0.4249 Acc: 0.1783\n",
      "\n",
      "Epoch 350/500\n",
      "train Loss: 0.4164 Acc: 0.2088\n",
      "val Loss: 0.4251 Acc: 0.1908\n",
      "\n",
      "Epoch 360/500\n",
      "train Loss: 0.4163 Acc: 0.2197\n",
      "val Loss: 0.4249 Acc: 0.1953\n",
      "\n",
      "Epoch 370/500\n",
      "train Loss: 0.4162 Acc: 0.2294\n",
      "val Loss: 0.4256 Acc: 0.2420\n",
      "\n",
      "Epoch 380/500\n",
      "train Loss: 0.4160 Acc: 0.2266\n",
      "val Loss: 0.4250 Acc: 0.1897\n",
      "\n",
      "Epoch 390/500\n",
      "train Loss: 0.4159 Acc: 0.2300\n",
      "val Loss: 0.4249 Acc: 0.2020\n",
      "\n",
      "Epoch 400/500\n",
      "train Loss: 0.4160 Acc: 0.2309\n",
      "val Loss: 0.4251 Acc: 0.2355\n",
      "\n",
      "Epoch 410/500\n",
      "train Loss: 0.4158 Acc: 0.2215\n",
      "val Loss: 0.4251 Acc: 0.2078\n",
      "\n",
      "Epoch 420/500\n",
      "train Loss: 0.4163 Acc: 0.2279\n",
      "val Loss: 0.4252 Acc: 0.1872\n",
      "\n",
      "Epoch 430/500\n",
      "train Loss: 0.4162 Acc: 0.2252\n",
      "val Loss: 0.4256 Acc: 0.2233\n",
      "\n",
      "Epoch 440/500\n",
      "train Loss: 0.4159 Acc: 0.2370\n",
      "val Loss: 0.4249 Acc: 0.2424\n",
      "\n",
      "Epoch 450/500\n",
      "train Loss: 0.4161 Acc: 0.2313\n",
      "val Loss: 0.4249 Acc: 0.2326\n",
      "\n",
      "Epoch 460/500\n",
      "train Loss: 0.4162 Acc: 0.2301\n",
      "val Loss: 0.4249 Acc: 0.2116\n",
      "\n",
      "Epoch 470/500\n",
      "train Loss: 0.4156 Acc: 0.2348\n",
      "val Loss: 0.4252 Acc: 0.2170\n",
      "\n",
      "Epoch 480/500\n",
      "train Loss: 0.4160 Acc: 0.2366\n",
      "val Loss: 0.4253 Acc: 0.2016\n",
      "\n",
      "Epoch 490/500\n",
      "train Loss: 0.4159 Acc: 0.2348\n",
      "val Loss: 0.4252 Acc: 0.2528\n",
      "\n",
      "Epoch 500/500\n",
      "train Loss: 0.4159 Acc: 0.2382\n",
      "val Loss: 0.4252 Acc: 0.1999\n",
      "\n",
      "Training complete in 20m 7s\n",
      "Best val Acc: 0.437706\n"
     ]
    }
   ],
   "source": [
    "# Regression pre-training\n",
    "\n",
    "model_name = 'LSTM_FCNs_multi'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "model_params['parameter']['input_size'] = input_size\n",
    "model_params['parameter']['alpha'] = 0 # cls = alpha, reg = 1-alpha\n",
    "model_params['best_model_path'] = f'./ckpt/{SOURCE_DATASET}/lstm_fcn_multi_{seq_len}_pre_reg.pt'\n",
    "\n",
    "data_source = mt.Multilearning(model_params,'self')\n",
    "data_source.build_model()\n",
    "\n",
    "best_model = data_source.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "\n",
    "os.makedirs(f'./ckpt/{SOURCE_DATASET}/', exist_ok=True)\n",
    "data_source.save_model(best_model, best_model_path=model_params[\"best_model_path\"])  # 모델 저장"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/500\n",
      "train Loss: 0.6975 Acc: 0.7953\n",
      "val Loss: 0.8778 Acc: 0.6664\n",
      "\n",
      "Epoch 10/500\n",
      "train Loss: 0.6354 Acc: 0.7991\n",
      "val Loss: 1.0414 Acc: 0.5470\n",
      "\n",
      "Epoch 20/500\n",
      "train Loss: 0.5764 Acc: 0.8014\n",
      "val Loss: 0.7580 Acc: 0.6948\n",
      "\n",
      "Epoch 30/500\n",
      "train Loss: 0.5260 Acc: 0.8040\n",
      "val Loss: 0.7173 Acc: 0.6623\n",
      "\n",
      "Epoch 40/500\n",
      "train Loss: 0.4891 Acc: 0.8044\n",
      "val Loss: 0.9273 Acc: 0.5653\n",
      "\n",
      "Epoch 50/500\n",
      "train Loss: 0.4634 Acc: 0.8068\n",
      "val Loss: 0.6815 Acc: 0.6776\n",
      "\n",
      "Epoch 60/500\n",
      "train Loss: 0.4518 Acc: 0.8098\n",
      "val Loss: 0.7367 Acc: 0.6551\n",
      "\n",
      "Epoch 70/500\n",
      "train Loss: 0.4472 Acc: 0.8110\n",
      "val Loss: 0.6893 Acc: 0.6363\n",
      "\n",
      "Epoch 80/500\n",
      "train Loss: 0.4395 Acc: 0.8136\n",
      "val Loss: 1.0120 Acc: 0.5924\n",
      "\n",
      "Epoch 90/500\n",
      "train Loss: 0.4378 Acc: 0.8160\n",
      "val Loss: 0.6410 Acc: 0.6894\n",
      "\n",
      "Epoch 100/500\n",
      "train Loss: 0.4368 Acc: 0.8155\n",
      "val Loss: 0.6824 Acc: 0.6556\n",
      "\n",
      "Epoch 110/500\n",
      "train Loss: 0.4322 Acc: 0.8209\n",
      "val Loss: 0.7379 Acc: 0.6493\n",
      "\n",
      "Epoch 120/500\n",
      "train Loss: 0.4300 Acc: 0.8181\n",
      "val Loss: 0.6162 Acc: 0.7122\n",
      "\n",
      "Epoch 130/500\n",
      "train Loss: 0.4295 Acc: 0.8221\n",
      "val Loss: 0.8231 Acc: 0.5982\n",
      "\n",
      "Epoch 140/500\n",
      "train Loss: 0.4274 Acc: 0.8232\n",
      "val Loss: 0.6693 Acc: 0.6845\n",
      "\n",
      "Epoch 150/500\n",
      "train Loss: 0.4235 Acc: 0.8274\n",
      "val Loss: 0.6482 Acc: 0.6861\n",
      "\n",
      "Epoch 160/500\n",
      "train Loss: 0.4215 Acc: 0.8300\n",
      "val Loss: 0.7732 Acc: 0.6312\n",
      "\n",
      "Epoch 170/500\n",
      "train Loss: 0.4221 Acc: 0.8287\n",
      "val Loss: 0.7071 Acc: 0.6417\n",
      "\n",
      "Epoch 180/500\n",
      "train Loss: 0.4198 Acc: 0.8290\n",
      "val Loss: 0.6492 Acc: 0.6999\n",
      "\n",
      "Epoch 190/500\n",
      "train Loss: 0.4166 Acc: 0.8314\n",
      "val Loss: 0.6507 Acc: 0.6721\n",
      "\n",
      "Epoch 200/500\n",
      "train Loss: 0.4168 Acc: 0.8324\n",
      "val Loss: 0.7005 Acc: 0.6521\n",
      "\n",
      "Epoch 210/500\n",
      "train Loss: 0.4128 Acc: 0.8344\n",
      "val Loss: 0.6557 Acc: 0.6697\n",
      "\n",
      "Epoch 220/500\n",
      "train Loss: 0.4134 Acc: 0.8338\n",
      "val Loss: 1.3797 Acc: 0.4987\n",
      "\n",
      "Epoch 230/500\n",
      "train Loss: 0.4105 Acc: 0.8378\n",
      "val Loss: 0.6353 Acc: 0.6852\n",
      "\n",
      "Epoch 240/500\n",
      "train Loss: 0.4051 Acc: 0.8425\n",
      "val Loss: 0.8147 Acc: 0.6638\n",
      "\n",
      "Epoch 250/500\n",
      "train Loss: 0.4090 Acc: 0.8379\n",
      "val Loss: 0.6586 Acc: 0.6792\n",
      "\n",
      "Epoch 260/500\n",
      "train Loss: 0.4029 Acc: 0.8416\n",
      "val Loss: 1.2940 Acc: 0.5139\n",
      "\n",
      "Epoch 270/500\n",
      "train Loss: 0.4051 Acc: 0.8409\n",
      "val Loss: 0.7693 Acc: 0.6276\n",
      "\n",
      "Epoch 280/500\n",
      "train Loss: 0.4006 Acc: 0.8436\n",
      "val Loss: 0.6372 Acc: 0.6944\n",
      "\n",
      "Epoch 290/500\n",
      "train Loss: 0.4038 Acc: 0.8424\n",
      "val Loss: 0.6652 Acc: 0.6864\n",
      "\n",
      "Epoch 300/500\n",
      "train Loss: 0.4005 Acc: 0.8438\n",
      "val Loss: 0.6258 Acc: 0.6941\n",
      "\n",
      "Epoch 310/500\n",
      "train Loss: 0.3989 Acc: 0.8477\n",
      "val Loss: 0.6536 Acc: 0.7037\n",
      "\n",
      "Epoch 320/500\n",
      "train Loss: 0.3966 Acc: 0.8479\n",
      "val Loss: 0.6702 Acc: 0.6764\n",
      "\n",
      "Epoch 330/500\n",
      "train Loss: 0.3942 Acc: 0.8486\n",
      "val Loss: 0.6925 Acc: 0.6731\n",
      "\n",
      "Epoch 340/500\n",
      "train Loss: 0.3921 Acc: 0.8516\n",
      "val Loss: 0.7380 Acc: 0.6366\n",
      "\n",
      "Epoch 350/500\n",
      "train Loss: 0.3898 Acc: 0.8543\n",
      "val Loss: 1.1095 Acc: 0.5773\n",
      "\n",
      "Epoch 360/500\n",
      "train Loss: 0.3911 Acc: 0.8529\n",
      "val Loss: 0.6922 Acc: 0.6768\n",
      "\n",
      "Epoch 370/500\n",
      "train Loss: 0.3888 Acc: 0.8550\n",
      "val Loss: 0.9239 Acc: 0.5972\n",
      "\n",
      "Epoch 380/500\n",
      "train Loss: 0.3865 Acc: 0.8574\n",
      "val Loss: 0.7285 Acc: 0.6581\n",
      "\n",
      "Epoch 390/500\n",
      "train Loss: 0.3866 Acc: 0.8555\n",
      "val Loss: 0.6970 Acc: 0.6767\n",
      "\n",
      "Epoch 400/500\n",
      "train Loss: 0.3841 Acc: 0.8590\n",
      "val Loss: 0.6503 Acc: 0.7046\n",
      "\n",
      "Epoch 410/500\n",
      "train Loss: 0.3843 Acc: 0.8602\n",
      "val Loss: 0.6677 Acc: 0.7035\n",
      "\n",
      "Epoch 420/500\n",
      "train Loss: 0.3810 Acc: 0.8603\n",
      "val Loss: 0.6737 Acc: 0.6789\n",
      "\n",
      "Epoch 430/500\n",
      "train Loss: 0.3817 Acc: 0.8605\n",
      "val Loss: 0.9766 Acc: 0.6523\n",
      "\n",
      "Epoch 440/500\n",
      "train Loss: 0.3823 Acc: 0.8590\n",
      "val Loss: 0.7538 Acc: 0.6620\n",
      "\n",
      "Epoch 450/500\n",
      "train Loss: 0.3788 Acc: 0.8622\n",
      "val Loss: 0.7428 Acc: 0.6911\n",
      "\n",
      "Epoch 460/500\n",
      "train Loss: 0.3759 Acc: 0.8662\n",
      "val Loss: 0.9534 Acc: 0.5984\n",
      "\n",
      "Epoch 470/500\n",
      "train Loss: 0.3771 Acc: 0.8647\n",
      "val Loss: 0.7509 Acc: 0.6592\n",
      "\n",
      "Epoch 480/500\n",
      "train Loss: 0.3753 Acc: 0.8662\n",
      "val Loss: 0.8565 Acc: 0.6370\n",
      "\n",
      "Epoch 490/500\n",
      "train Loss: 0.3749 Acc: 0.8662\n",
      "val Loss: 0.9319 Acc: 0.5663\n",
      "\n",
      "Epoch 500/500\n",
      "train Loss: 0.3733 Acc: 0.8668\n",
      "val Loss: 0.8446 Acc: 0.5726\n",
      "\n",
      "Training complete in 20m 44s\n",
      "Best val Acc: 0.726265\n"
     ]
    }
   ],
   "source": [
    "# pre Classification fine-training\n",
    "\n",
    "model_name = 'LSTM_FCNs_multi'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "model_params['parameter']['input_size'] = input_size\n",
    "model_params['parameter']['alpha'] = 0.5 # cls = alpha, reg = 1-alpha\n",
    "model_params['best_model_path'] = f'./ckpt/{SOURCE_DATASET}/lstm_fcn_multi_{seq_len}_pre_cls.pt' ## pre-train\n",
    "\n",
    "data_source = mt.Multilearning(model_params, 'self') ## 자기자신 데이터로 학습 하는 option : self\n",
    "data_source.build_model()\n",
    "\n",
    "best_model = data_source.train_model(train_x, train_y, valid_x, valid_y, option='target')  # 모델 학습\n",
    "\n",
    "os.makedirs(f'./ckpt/{SOURCE_DATASET}/', exist_ok=True)\n",
    "data_source.save_model(best_model, best_model_path=f'./ckpt/{SOURCE_DATASET}/lstm_fcn_pre_cls_fine.pt')  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/500\n",
      "train Loss: 1.0570 Acc: 0.4685\n",
      "val Loss: 1.0424 Acc: 0.4843\n",
      "\n",
      "Epoch 10/500\n",
      "train Loss: 0.8391 Acc: 0.6460\n",
      "val Loss: 0.8411 Acc: 0.6414\n",
      "\n",
      "Epoch 20/500\n",
      "train Loss: 0.7500 Acc: 0.6765\n",
      "val Loss: 0.8024 Acc: 0.6346\n",
      "\n",
      "Epoch 30/500\n",
      "train Loss: 0.6837 Acc: 0.6870\n",
      "val Loss: 0.8025 Acc: 0.5846\n",
      "\n",
      "Epoch 40/500\n",
      "train Loss: 0.6281 Acc: 0.6940\n",
      "val Loss: 0.8123 Acc: 0.6017\n",
      "\n",
      "Epoch 50/500\n",
      "train Loss: 0.5855 Acc: 0.7049\n",
      "val Loss: 0.8683 Acc: 0.5565\n",
      "\n",
      "Epoch 60/500\n",
      "train Loss: 0.5629 Acc: 0.7085\n",
      "val Loss: 0.6599 Acc: 0.6616\n",
      "\n",
      "Epoch 70/500\n",
      "train Loss: 0.5507 Acc: 0.7170\n",
      "val Loss: 0.6158 Acc: 0.6670\n",
      "\n",
      "Epoch 80/500\n",
      "train Loss: 0.5403 Acc: 0.7262\n",
      "val Loss: 0.6718 Acc: 0.6231\n",
      "\n",
      "Epoch 90/500\n",
      "train Loss: 0.5342 Acc: 0.7301\n",
      "val Loss: 0.6967 Acc: 0.5996\n",
      "\n",
      "Epoch 100/500\n",
      "train Loss: 0.5271 Acc: 0.7377\n",
      "val Loss: 0.7648 Acc: 0.5997\n",
      "\n",
      "Epoch 110/500\n",
      "train Loss: 0.5212 Acc: 0.7447\n",
      "val Loss: 0.7136 Acc: 0.6361\n",
      "\n",
      "Epoch 120/500\n",
      "train Loss: 0.5147 Acc: 0.7468\n",
      "val Loss: 0.6969 Acc: 0.6315\n",
      "\n",
      "Epoch 130/500\n",
      "train Loss: 0.5105 Acc: 0.7521\n",
      "val Loss: 0.7763 Acc: 0.6125\n",
      "\n",
      "Epoch 140/500\n",
      "train Loss: 0.5044 Acc: 0.7556\n",
      "val Loss: 0.6002 Acc: 0.6971\n",
      "\n",
      "Epoch 150/500\n",
      "train Loss: 0.4978 Acc: 0.7628\n",
      "val Loss: 0.7224 Acc: 0.6286\n",
      "\n",
      "Epoch 160/500\n",
      "train Loss: 0.4944 Acc: 0.7663\n",
      "val Loss: 0.6931 Acc: 0.6231\n",
      "\n",
      "Epoch 170/500\n",
      "train Loss: 0.4896 Acc: 0.7697\n",
      "val Loss: 0.6403 Acc: 0.6653\n",
      "\n",
      "Epoch 180/500\n",
      "train Loss: 0.4864 Acc: 0.7725\n",
      "val Loss: 0.5981 Acc: 0.6914\n",
      "\n",
      "Epoch 190/500\n",
      "train Loss: 0.4802 Acc: 0.7776\n",
      "val Loss: 0.7568 Acc: 0.6321\n",
      "\n",
      "Epoch 200/500\n",
      "train Loss: 0.4781 Acc: 0.7778\n",
      "val Loss: 0.8799 Acc: 0.5609\n",
      "\n",
      "Epoch 210/500\n",
      "train Loss: 0.4741 Acc: 0.7813\n",
      "val Loss: 1.0107 Acc: 0.6012\n",
      "\n",
      "Epoch 220/500\n",
      "train Loss: 0.4704 Acc: 0.7844\n",
      "val Loss: 0.8531 Acc: 0.5861\n",
      "\n",
      "Epoch 230/500\n",
      "train Loss: 0.4669 Acc: 0.7895\n",
      "val Loss: 0.6627 Acc: 0.6680\n",
      "\n",
      "Epoch 240/500\n",
      "train Loss: 0.4633 Acc: 0.7927\n",
      "val Loss: 0.7131 Acc: 0.6743\n",
      "\n",
      "Epoch 250/500\n",
      "train Loss: 0.4614 Acc: 0.7944\n",
      "val Loss: 0.6751 Acc: 0.6547\n",
      "\n",
      "Epoch 260/500\n",
      "train Loss: 0.4578 Acc: 0.7967\n",
      "val Loss: 0.6833 Acc: 0.6442\n",
      "\n",
      "Epoch 270/500\n",
      "train Loss: 0.4526 Acc: 0.8031\n",
      "val Loss: 0.7659 Acc: 0.6476\n",
      "\n",
      "Epoch 280/500\n",
      "train Loss: 0.4531 Acc: 0.7996\n",
      "val Loss: 0.8861 Acc: 0.5714\n",
      "\n",
      "Epoch 290/500\n",
      "train Loss: 0.4501 Acc: 0.8040\n",
      "val Loss: 0.7736 Acc: 0.6686\n",
      "\n",
      "Epoch 300/500\n",
      "train Loss: 0.4462 Acc: 0.8080\n",
      "val Loss: 0.6343 Acc: 0.6713\n",
      "\n",
      "Epoch 310/500\n",
      "train Loss: 0.4428 Acc: 0.8086\n",
      "val Loss: 0.6719 Acc: 0.6887\n",
      "\n",
      "Epoch 320/500\n",
      "train Loss: 0.4421 Acc: 0.8105\n",
      "val Loss: 0.6239 Acc: 0.6858\n",
      "\n",
      "Epoch 330/500\n",
      "train Loss: 0.4404 Acc: 0.8086\n",
      "val Loss: 0.7025 Acc: 0.6521\n",
      "\n",
      "Epoch 340/500\n",
      "train Loss: 0.4363 Acc: 0.8158\n",
      "val Loss: 0.6748 Acc: 0.6659\n",
      "\n",
      "Epoch 350/500\n",
      "train Loss: 0.4341 Acc: 0.8175\n",
      "val Loss: 0.6565 Acc: 0.6688\n",
      "\n",
      "Epoch 360/500\n",
      "train Loss: 0.4318 Acc: 0.8196\n",
      "val Loss: 0.6379 Acc: 0.6891\n",
      "\n",
      "Epoch 370/500\n",
      "train Loss: 0.4291 Acc: 0.8219\n",
      "val Loss: 0.6937 Acc: 0.6752\n",
      "\n",
      "Epoch 380/500\n",
      "train Loss: 0.4311 Acc: 0.8204\n",
      "val Loss: 0.6700 Acc: 0.6830\n",
      "\n",
      "Epoch 390/500\n",
      "train Loss: 0.4285 Acc: 0.8229\n",
      "val Loss: 0.6831 Acc: 0.6613\n",
      "\n",
      "Epoch 400/500\n",
      "train Loss: 0.4246 Acc: 0.8238\n",
      "val Loss: 0.6656 Acc: 0.6776\n",
      "\n",
      "Epoch 410/500\n",
      "train Loss: 0.4233 Acc: 0.8244\n",
      "val Loss: 0.6992 Acc: 0.6806\n",
      "\n",
      "Epoch 420/500\n",
      "train Loss: 0.4172 Acc: 0.8307\n",
      "val Loss: 0.8116 Acc: 0.5693\n",
      "\n",
      "Epoch 430/500\n",
      "train Loss: 0.4186 Acc: 0.8296\n",
      "val Loss: 0.7677 Acc: 0.6471\n",
      "\n",
      "Epoch 440/500\n",
      "train Loss: 0.4156 Acc: 0.8310\n",
      "val Loss: 0.7454 Acc: 0.6497\n",
      "\n",
      "Epoch 450/500\n",
      "train Loss: 0.4155 Acc: 0.8339\n",
      "val Loss: 0.6909 Acc: 0.6818\n",
      "\n",
      "Epoch 460/500\n",
      "train Loss: 0.4132 Acc: 0.8325\n",
      "val Loss: 1.0235 Acc: 0.5195\n",
      "\n",
      "Epoch 470/500\n",
      "train Loss: 0.4122 Acc: 0.8343\n",
      "val Loss: 0.7790 Acc: 0.6509\n",
      "\n",
      "Epoch 480/500\n",
      "train Loss: 0.4113 Acc: 0.8353\n",
      "val Loss: 0.6593 Acc: 0.6712\n",
      "\n",
      "Epoch 490/500\n",
      "train Loss: 0.4096 Acc: 0.8371\n",
      "val Loss: 0.7684 Acc: 0.6623\n",
      "\n",
      "Epoch 500/500\n",
      "train Loss: 0.4059 Acc: 0.8384\n",
      "val Loss: 0.8531 Acc: 0.5949\n",
      "\n",
      "Training complete in 20m 39s\n",
      "Best val Acc: 0.723270\n"
     ]
    }
   ],
   "source": [
    "# pre Regression fine-training\n",
    "\n",
    "model_name = 'LSTM_FCNs_multi'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "model_params['parameter']['input_size'] = input_size\n",
    "model_params['parameter']['alpha'] = 0.5 # cls = alpha, reg = 1-alpha\n",
    "model_params['best_model_path'] = f'./ckpt/{SOURCE_DATASET}/lstm_fcn_multi_{seq_len}_pre_reg.pt' ## pre-train\n",
    "\n",
    "data_source = mt.Multilearning(model_params, 'self') ## 자기자신 데이터로 학습 하는 option : self\n",
    "data_source.build_model()\n",
    "\n",
    "best_model = data_source.train_model(train_x, train_y, valid_x, valid_y, option='target')  # 모델 학습\n",
    "\n",
    "os.makedirs(f'./ckpt/{SOURCE_DATASET}/', exist_ok=True)\n",
    "data_source.save_model(best_model, best_model_path=f'./ckpt/{SOURCE_DATASET}/lstm_fcn_pre_reg_fine.pt')  # 모델 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
